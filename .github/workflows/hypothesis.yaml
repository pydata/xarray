name: Slow Hypothesis CI
on:
  push:
    branches:
      - "main"
  pull_request:
    branches:
      - "main"
    types: [opened, reopened, synchronize, labeled]
  schedule:
    - cron: "0 0 * * *" # Daily “At 00:00” UTC
  workflow_dispatch: # allows you to trigger manually

env:
  FORCE_COLOR: 3
  PIXI_VERSION: "v0.58.0"

jobs:
  detect-ci-trigger:
    name: detect ci trigger
    runs-on: ubuntu-latest
    if: |
      github.repository == 'pydata/xarray'
      && (github.event_name == 'push' || github.event_name == 'pull_request' || github.event_name == 'schedule')
      && !contains(github.event.pull_request.labels.*.name, 'skip-ci')
    outputs:
      triggered: ${{ steps.detect-trigger.outputs.trigger-found }}
    steps:
      - uses: actions/checkout@v6
        with:
          fetch-depth: 2
      - uses: xarray-contrib/ci-trigger@v1
        id: detect-trigger
        with:
          keyword: "[skip-ci]"

  cache-pixi-lock:
    uses: ./.github/workflows/cache-pixi-lock.yml
    with:
      pixi-version: "v0.58.0" # keep in sync with env var above

  hypothesis:
    name: Slow Hypothesis Tests
    runs-on: "ubuntu-latest"
    needs: [detect-ci-trigger, cache-pixi-lock]
    if: |
      always()
      && (
          needs.detect-ci-trigger.outputs.triggered == 'false'
          && ( (github.event_name == 'schedule' || github.event_name == 'workflow_dispatch')
              || contains( github.event.pull_request.labels.*.name, 'run-slow-hypothesis'))
      )
    defaults:
      run:
        shell: bash -l {0}

    env:
      PIXI_ENV: "test-py313"

    steps:
      - uses: actions/checkout@v6
        with:
          fetch-depth: 0 # Fetch all history for all branches and tags.

      - name: Restore cached pixi lockfile
        uses: actions/cache/restore@v4
        id: restore-pixi-lock
        with:
          enableCrossOsArchive: true
          path: |
            pixi.lock
          key: ${{ needs.cache-pixi-lock.outputs.cache-id }}
      - uses: prefix-dev/setup-pixi@v0.9.3
        with:
          pixi-version: ${{ env.PIXI_VERSION }}
          cache: true
          environments: ${{ env.PIXI_ENV }}
          cache-write: ${{ github.event_name == 'push' && github.ref_name == 'main' }}

      - name: set environment variables
        run: |
          echo "TODAY=$(date  +'%Y-%m-%d')" >> $GITHUB_ENV
          echo "PYTHON_VERSION=$(pixi run -e ${{env.PIXI_ENV}} python --version | cut -d' ' -f2 | cut -d. -f1,2)" >> $GITHUB_ENV

      - name: Version info
        run: |
          pixi run -e ${{ env.PIXI_ENV }} python xarray/util/print_versions.py

      # https://github.com/actions/cache/blob/main/tips-and-workarounds.md#update-a-cache
      - name: Restore cached hypothesis directory
        id: restore-hypothesis-cache
        uses: actions/cache/restore@v4
        with:
          path: .hypothesis/
          key: cache-hypothesis-${{ runner.os }}-${{ github.run_id }}
          restore-keys: |
            cache-hypothesis-

      - name: Run slow Hypothesis tests
        if: success()
        id: status
        run: |
          pixi run -e ${{ env.PIXI_ENV }} python -m pytest --hypothesis-show-statistics --run-slow-hypothesis properties/*.py \
            --report-log output-${{ env.PIXI_ENV }}-log.jsonl

      # explicitly save the cache so it gets updated, also do this even if it fails.
      - name: Save cached hypothesis directory
        id: save-hypothesis-cache
        if: always() && steps.status.outcome != 'skipped'
        uses: actions/cache/save@v4
        with:
          path: .hypothesis/
          key: cache-hypothesis-${{ runner.os }}-${{ github.run_id }}

      - name: Generate and publish the report
        if: |
          failure()
          && steps.status.outcome == 'failure'
          && github.event_name == 'schedule'
          && github.repository_owner == 'pydata'
        uses: scientific-python/issue-from-pytest-log-action@v1
        with:
          log-path: output-${{ env.PIXI_ENV }}-log.jsonl
          issue-title: "Nightly Hypothesis tests failed"
          issue-label: "topic-hypothesis"
