name: Benchmark

on:
  pull_request:
    types: [opened, reopened, synchronize, labeled]
  workflow_dispatch:

env:
  PR_HEAD_LABEL: ${{ github.event.pull_request.head.label }}

jobs:
  benchmark:
    if: ${{ contains( github.event.pull_request.labels.*.name, 'run-benchmark') && github.event_name == 'pull_request' || contains( github.event.pull_request.labels.*.name, 'topic-performance') && github.event_name == 'pull_request' || github.event_name == 'workflow_dispatch' }}
    name: Linux
    runs-on: ubuntu-latest
    env:
      ASV_DIR: "./asv_bench"
      CONDA_ENV_FILE: ci/requirements/environment-benchmark.yml

    steps:
      # We need the full repo to avoid this issue
      # https://github.com/actions/checkout/issues/23
      - uses: actions/checkout@v5
        with:
          fetch-depth: 0

      - name: Set up conda environment
        # uses: mamba-org/setup-micromamba@v2
        uses: conda-incubator/setup-miniconda@v2
        with:
          micromamba-version: "1.5.10-0"
          environment-file: ${{env.CONDA_ENV_FILE}}
          environment-name: xarray-benchmark
          cache-environment: true
          cache-environment-key: "${{runner.os}}-${{runner.arch}}-py${{env.PYTHON_VERSION}}-${{env.TODAY}}-${{hashFiles(env.CONDA_ENV_FILE)}}-benchmark"
          # add "build" because of https://github.com/airspeed-velocity/asv/issues/1385
          create-args: >-
            asv
            python-build
            mamba<=1.5.10

      - name: Run benchmarks
        shell: bash -l {0}
        id: benchmark
        env:
          OPENBLAS_NUM_THREADS: 1
          MKL_NUM_THREADS: 1
          OMP_NUM_THREADS: 1
          ASV_FACTOR: 1.5
          ASV_SKIP_SLOW: 1
        run: |
          set -x
          # ID this runner
          asv machine --yes
          echo "Baseline:  ${{ github.event.pull_request.base.sha }} (${{ github.event.pull_request.base.label }})"
          echo "Contender: ${GITHUB_SHA} ($PR_HEAD_LABEL)"
          # Run benchmarks for current commit against base
          ASV_OPTIONS="--split --show-stderr --factor $ASV_FACTOR"
          # asv continuous $ASV_OPTIONS ${{ github.event.pull_request.base.sha }} ${GITHUB_SHA} \
              # | sed "/Traceback \|failed$\|PERFORMANCE DECREASED/ s/^/::error::/" \
              # | tee benchmarks.log
          asv continuous origin/${{github.base_ref}} HEAD $ASV_OPTIONS \
              | sed "/Traceback \|failed$\|PERFORMANCE DECREASED/ s/^/::error::/" \
              | tee benchmarks.log
          asv compare origin/${{github.base_ref}} HEAD --split --sort ratio \
              | tee -a asv_compare.log
          mkdir comment_log
          mv asv_compare.log comment_log/
          # Report and export results for subsequent steps
          if grep "Traceback \|failed\|PERFORMANCE DECREASED" benchmarks.log > /dev/null ; then
              exit 1
          fi
        working-directory: ${{ env.ASV_DIR }}

      - name: Save PR Number
        env:
          PR_NUMBER: ${{github.event.pull_request.number}}
        run: |
          echo $PR_NUMBER > ./comment_log/pr_number
        working-directory: ${{ env.ASV_DIR }}

      - name: Upload the compare log
        uses: actions/upload-artifact@v4
        with:
          name: comment_log
          path: benchmark/comment_log/

      - name: Add instructions to artifact
        if: always()
        run: |
          cp benchmarks/README_CI.md benchmarks.log .asv/results/
        working-directory: ${{ env.ASV_DIR }}

      - uses: actions/upload-artifact@v4
        if: always()
        with:
          name: asv-benchmark-results-${{ runner.os }}
          path: ${{ env.ASV_DIR }}/.asv/results
